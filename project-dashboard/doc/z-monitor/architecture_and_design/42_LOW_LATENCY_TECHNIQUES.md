# Low Latency Techniques and Tools

**Document ID:** DESIGN-042  
**Version:** 1.0  
**Status:** Approved  
**Last Updated:** 2025-11-27

---

This document provides a comprehensive guide to low-latency techniques, tools, and libraries for the Z Monitor application. It covers when to use specific techniques, which libraries to choose, and implementation guidelines for critical path operations.

> **üìã Related Documents:**
> - [Thread Model (12_THREAD_MODEL.md)](./12_THREAD_MODEL.md) - Latency targets and thread architecture ‚≠ê
> - [Memory & Resource Management (23_MEMORY_RESOURCE_MANAGEMENT.md)](./23_MEMORY_RESOURCE_MANAGEMENT.md) - Memory management patterns
> - [Data Caching Strategy (36_DATA_CACHING_STRATEGY.md)](./36_DATA_CACHING_STRATEGY.md) - Critical path caching
> - [Performance Requirements](../../requirements/04_NON_FUNCTIONAL_REQUIREMENTS.md) - Latency targets and performance requirements
> - [Benchmark Strategy (40_BENCHMARK_AND_PERFORMANCE_MEASUREMENT.md)](./40_BENCHMARK_AND_PERFORMANCE_MEASUREMENT.md) - Performance measurement

---

## 1. Overview

The Z Monitor application has strict latency requirements, particularly for alarm detection (< 50ms). This document provides:

- **Low-latency techniques** for critical path operations
- **Tool and library recommendations** with performance characteristics
- **Decision guidelines** for when to use which technique
- **Implementation plans** for Z Monitor-specific scenarios

### 1.1 Critical Latency Targets

| Operation | Target Latency | Criticality | Path |
|-----------|---------------|-------------|------|
| Sensor read ‚Üí sample enqueued | < 1 ms | Critical | Sensor I/O ‚Üí RT Thread |
| Sample ‚Üí processed (derived metrics) | < 5 ms | Critical | RT Thread processing |
| Alarm detection ‚Üí UI visible | < 50 ms | **CRITICAL** | RT Thread ‚Üí UI Thread |
| DB write (background batch) | < 200 ms | Normal | Background Thread |
| DB write (critical alarm) | < 100 ms | High | Background Thread |
| UI response (user interaction) | < 500 ms | Must Have | UI Thread |

---

## 2. Low-Latency Techniques

### 2.1 Pre-Allocation

**Principle:** Allocate all memory at startup, never during critical path operations.

**When to Use:**
- ‚úÖ Real-time threads (RT Thread, Sensor I/O Thread)
- ‚úÖ High-frequency operations (per-sample processing)
- ‚úÖ Alarm detection path
- ‚úÖ Lock-free queue buffers
- ‚úÖ String buffers for logging

**When NOT to Use:**
- ‚ùå One-time initialization operations
- ‚ùå Background threads (unless performance critical)
- ‚ùå Operations with unpredictable memory needs

**Implementation:**
```cpp
// Pre-allocate at startup
class SignalProcessor {
private:
    static constexpr size_t BUFFER_SIZE = 1024;
    std::array<float, BUFFER_SIZE> m_sampleBuffer;  // Stack or member
    std::array<float, BUFFER_SIZE> m_filterBuffer;
    
public:
    SignalProcessor() {
        // Buffers allocated, no heap allocation during processing
    }
    
    void processSample(float sample) {
        // Zero allocation - uses pre-allocated buffers
        m_sampleBuffer[m_writeIndex] = sample;
        // Process...
    }
};
```

**Z Monitor Usage:**
- `VitalsCache` - Pre-allocated for 3-day capacity (~39 MB)
- `WaveformCache` - Pre-allocated circular buffer (30 seconds)
- `LockFreeQueue` buffers - Pre-allocated ring buffers
- Alarm detection structures - Pre-allocated threshold check buffers

---

### 2.2 Lock-Free Data Structures

**Principle:** Use lock-free queues and atomic operations to avoid mutex contention.

**When to Use:**
- ‚úÖ High-frequency inter-thread communication
- ‚úÖ Real-time thread ‚Üí Background thread (SPSC)
- ‚úÖ Multiple producers ‚Üí Single consumer (MPSC)
- ‚úÖ Ring buffers for waveform samples
- ‚úÖ Logging queues

**When NOT to Use:**
- ‚ùå Low-frequency operations (mutex overhead acceptable)
- ‚ùå Complex data structures requiring consistency
- ‚ùå Operations where blocking is acceptable

**Z Monitor Usage:**
- Sensor I/O ‚Üí RT Thread: SPSC lock-free queue
- RT Thread ‚Üí Database Thread: MPSC lock-free queue (telemetry batches)
- RT Thread ‚Üí UI Thread: Qt signals (queued connection, acceptable latency)

---

### 2.3 Zero-Copy Patterns

**Principle:** Minimize data copying by using references, move semantics, and shared memory.

**When to Use:**
- ‚úÖ Large data structures (TelemetryBatch, waveform arrays)
- ‚úÖ Cross-thread data passing
- ‚úÖ Serialization/deserialization paths
- ‚úÖ Logging message construction

**When NOT to Use:**
- ‚ùå Small POD types (copy is cheaper than indirection)
- ‚ùå Simple value objects (PatientIdentity, VitalRecord)

**Implementation:**
```cpp
// Good: Move semantics (zero copy)
void enqueueTelemetry(TelemetryBatch&& batch) {
    m_queue.enqueue(std::move(batch));  // Move, no copy
}

// Good: Pass by reference
void processVitals(const VitalRecord& record) {
    // No copy, just reference
}

// Avoid: Unnecessary copy
void processVitals(VitalRecord record) {  // Copy made
    // ...
}
```

**Z Monitor Usage:**
- `TelemetryBatch` - Moved between threads, not copied
- Waveform samples - Passed by reference in processing pipeline
- Log entries - Moved to logging queue

---

### 2.4 Object Pooling

**Principle:** Reuse objects instead of allocating/deallocating repeatedly.

**When to Use:**
- ‚úÖ High-frequency object creation (TelemetryBatch objects)
- ‚úÖ Temporary objects in hot paths
- ‚úÖ Objects with expensive construction
- ‚úÖ Real-time threads

**When NOT to Use:**
- ‚ùå One-time object creation
- ‚ùå Objects with complex state (hard to reset)
- ‚ùå Background threads (unless performance critical)

**Z Monitor Usage:**
- `TelemetryBatch` objects - Pooled for RT Thread ‚Üí Database Thread
- Log buffer objects - Pooled for high-frequency logging
- Network request objects - Pooled for telemetry transmission

---

### 2.5 CPU Affinity and Priority

**Principle:** Pin threads to CPU cores and set high priority for real-time operations.

**When to Use:**
- ‚úÖ Real-time threads (RT Thread, Sensor I/O Thread)
- ‚úÖ Critical path operations (alarm detection)
- ‚úÖ High-frequency processing

**When NOT to Use:**
- ‚ùå Background threads (normal priority sufficient)
- ‚ùå UI thread (should remain responsive but not starve other threads)
- ‚ùå Database thread (I/O bound, priority less important)

**Implementation:**
```cpp
// Set thread priority and affinity
QThread* rtThread = new QThread();
rtThread->setPriority(QThread::HighPriority);

#ifdef Q_OS_LINUX
    // Pin to CPU core 0
    cpu_set_t cpuset;
    CPU_ZERO(&cpuset);
    CPU_SET(0, &cpuset);
    pthread_setaffinity_np(pthread_self(), sizeof(cpu_set_t), &cpuset);
    
    // Set real-time scheduling
    struct sched_param param;
    param.sched_priority = 50;  // High priority
    pthread_setschedparam(pthread_self(), SCHED_FIFO, &param);
#endif
```

**Z Monitor Usage:**
- RT Thread: High priority, pinned to CPU core 0
- Sensor I/O Thread: High priority, pinned to CPU core 1
- Database Thread: Normal priority
- Network Thread: Normal priority

---

### 2.6 Batch Processing

**Principle:** Process multiple items together to amortize overhead.

**When to Use:**
- ‚úÖ Database writes (batch inserts)
- ‚úÖ Network transmission (batch telemetry)
- ‚úÖ Log file writes
- ‚úÖ Cache persistence

**When NOT to Use:**
- ‚ùå Real-time operations (alarm detection must be immediate)
- ‚ùå User interactions (must respond immediately)
- ‚ùå Critical path operations

**Z Monitor Usage:**
- Database writes: Batch 10 vitals records per transaction
- Telemetry transmission: Batch vitals every 10 seconds
- Cache persistence: Batch write every 10 minutes

---

### 2.7 Memory-Mapped Files

**Principle:** Use memory-mapped files for large data structures to avoid copying.

**When to Use:**
- ‚úÖ Large read-only data (patient lookup cache)
- ‚úÖ Shared memory between processes
- ‚úÖ Large log files

**When NOT to Use:**
- ‚ùå Small data structures
- ‚ùå Frequently updated data (overhead of sync)
- ‚ùå Real-time operations (page faults can cause jitter)

**Z Monitor Usage:**
- Patient lookup cache (if large enough to benefit)
- Historical trend data (read-only access)

---

## 3. Tools and Libraries

### 3.1 Lock-Free Queue Libraries

#### 3.1.1 boost::lockfree::spsc_queue

**Type:** Single Producer, Single Consumer  
**Performance:** Fastest for SPSC scenarios  
**Latency:** < 10 ns per operation  
**Memory:** Pre-allocated ring buffer

**When to Use:**
- ‚úÖ Sensor I/O ‚Üí RT Thread (one sensor, one processor)
- ‚úÖ RT Thread ‚Üí Database Thread (if single producer)
- ‚úÖ Highest performance SPSC scenarios

**When NOT to Use:**
- ‚ùå Multiple producers (use MPSC queue)
- ‚ùå Multiple consumers (use MPMC queue)

**Implementation:**
```cpp
#include <boost/lockfree/spsc_queue.hpp>

// Pre-allocate queue
boost::lockfree::spsc_queue<Sample, boost::lockfree::capacity<4096>> sampleQueue;

// Producer (Sensor I/O Thread)
void onSensorData(const Sample& sample) {
    sampleQueue.push(sample);  // Lock-free, < 10 ns
}

// Consumer (RT Thread)
void processSamples() {
    Sample sample;
    while (sampleQueue.pop(sample)) {
        processSample(sample);  // Process without blocking
    }
}
```

**Z Monitor Usage:**
- **Sensor I/O ‚Üí RT Thread:** `boost::lockfree::spsc_queue<SensorSample, capacity<4096>>`
- **Performance:** < 1 ms latency target met

---

#### 3.1.2 boost::lockfree::queue

**Type:** Multiple Producer, Multiple Consumer  
**Performance:** Fast for MPSC/MPMC scenarios  
**Latency:** < 50 ns per operation  
**Memory:** Dynamic allocation (nodes)

**When to Use:**
- ‚úÖ Multiple producers ‚Üí Single consumer (MPSC)
- ‚úÖ Multiple producers ‚Üí Multiple consumers (MPMC)
- ‚úÖ RT Thread ‚Üí Database Thread (if multiple RT workers)

**When NOT to Use:**
- ‚ùå SPSC scenarios (spsc_queue is faster)
- ‚ùå Zero-allocation requirements (uses dynamic allocation)

**Implementation:**
```cpp
#include <boost/lockfree/queue.hpp>

boost::lockfree::queue<TelemetryBatch> telemetryQueue;

// Multiple producers (RT Thread workers)
void enqueueTelemetry(TelemetryBatch&& batch) {
    telemetryQueue.push(std::move(batch));  // Lock-free, < 50 ns
}

// Single consumer (Database Thread)
void persistTelemetry() {
    TelemetryBatch batch;
    while (telemetryQueue.pop(batch)) {
        persistBatch(batch);  // Batch write to database
    }
}
```

**Z Monitor Usage:**
- **RT Thread ‚Üí Database Thread:** `boost::lockfree::queue<TelemetryBatch>` (MPSC)
- **Performance:** < 200 ms latency target for background persistence

---

#### 3.1.3 moodycamel::ConcurrentQueue

**Type:** Multiple Producer, Multiple Consumer  
**Performance:** Very fast, header-only  
**Latency:** < 30 ns per operation  
**Memory:** Pre-allocated blocks with dynamic growth

**When to Use:**
- ‚úÖ MPSC/MPMC scenarios
- ‚úÖ Header-only requirement (no linking)
- ‚úÖ High throughput requirements
- ‚úÖ Variable queue sizes

**When NOT to Use:**
- ‚ùå SPSC scenarios (spsc_queue is faster)
- ‚ùå Fixed-size requirement (grows dynamically)

**Implementation:**
```cpp
#include "concurrentqueue.h"

moodycamel::ConcurrentQueue<LogEntry> logQueue;

// Multiple producers
void logMessage(const LogEntry& entry) {
    logQueue.enqueue(entry);  // Lock-free, < 30 ns
}

// Single consumer (Database I/O Thread)
void flushLogs() {
    LogEntry entry;
    while (logQueue.try_dequeue(entry)) {
        writeLogEntry(entry);
    }
}
```

**Z Monitor Usage:**
- **Logging Queue:** `moodycamel::ConcurrentQueue<LogEntry>` (MPSC)
- **Alternative to boost::lockfree::queue** if header-only preferred

---

#### 3.1.4 Custom SPSC Ring Buffer

**Type:** Single Producer, Single Consumer  
**Performance:** Fastest (no library overhead)  
**Latency:** < 5 ns per operation  
**Memory:** Pre-allocated array

**When to Use:**
- ‚úÖ SPSC scenarios with highest performance requirements
- ‚úÖ Zero-allocation requirement
- ‚úÖ Minimal dependencies
- ‚úÖ Custom behavior needed

**When NOT to Use:**
- ‚ùå Multiple producers/consumers
- ‚ùå Variable queue sizes
- ‚ùå When library maintenance is preferred

**Implementation:**
```cpp
template<typename T, size_t Size>
class SPSCRingBuffer {
private:
    std::array<T, Size> m_buffer;
    std::atomic<size_t> m_writeIndex{0};
    std::atomic<size_t> m_readIndex{0};
    
public:
    bool push(const T& item) {
        size_t next = (m_writeIndex.load() + 1) % Size;
        if (next == m_readIndex.load()) {
            return false;  // Full
        }
        m_buffer[m_writeIndex.load()] = item;
        m_writeIndex.store(next, std::memory_order_release);
        return true;
    }
    
    bool pop(T& item) {
        if (m_readIndex.load() == m_writeIndex.load()) {
            return false;  // Empty
        }
        item = m_buffer[m_readIndex.load()];
        m_readIndex.store((m_readIndex.load() + 1) % Size, std::memory_order_acquire);
        return true;
    }
};
```

**Z Monitor Usage:**
- **Waveform samples:** Custom SPSC ring buffer (highest performance)
- **Performance:** < 1 ms latency for sensor ‚Üí RT Thread

---

### 3.2 Memory Management Libraries

#### 3.2.1 Custom Object Pool

**Type:** Object pooling utility  
**Performance:** Eliminates allocation overhead  
**Latency:** < 10 ns per acquire/release

**When to Use:**
- ‚úÖ High-frequency object creation (TelemetryBatch)
- ‚úÖ Real-time threads
- ‚úÖ Objects with expensive construction

**Implementation:** See [23_MEMORY_RESOURCE_MANAGEMENT.md](./23_MEMORY_RESOURCE_MANAGEMENT.md) Section 2.4

**Z Monitor Usage:**
- **TelemetryBatch pool:** Pool of 100 pre-allocated batches
- **Location:** `src/infrastructure/utils/ObjectPool.h/cpp`

---

#### 3.2.2 boost::pool

**Type:** Memory pool allocator  
**Performance:** Fast allocation for fixed-size objects  
**Latency:** < 20 ns per allocation

**When to Use:**
- ‚úÖ Fixed-size object allocation
- ‚úÖ High-frequency allocations
- ‚úÖ When boost is already a dependency

**When NOT to Use:**
- ‚ùå Variable-size objects
- ‚ùå Minimal dependency requirement

**Z Monitor Usage:**
- **Alternative to custom ObjectPool** if boost is available
- **Not currently planned** (custom implementation preferred)

---

### 3.3 Profiling and Measurement Tools

#### 3.3.1 Google Benchmark

**Type:** Microbenchmark framework  
**Performance:** Low overhead measurement  
**Latency:** < 1% measurement overhead

**When to Use:**
- ‚úÖ Performance regression testing
- ‚úÖ Latency measurement
- ‚úÖ Throughput measurement
- ‚úÖ CI/CD performance monitoring

**Z Monitor Usage:**
- **Alarm detection latency:** `bench_alarm_detection_latency`
- **Queue performance:** `bench_lockfree_queue_throughput`
- **See:** [40_BENCHMARK_AND_PERFORMANCE_MEASUREMENT.md](./40_BENCHMARK_AND_PERFORMANCE_MEASUREMENT.md)

---

#### 3.3.2 perf (Linux)

**Type:** Performance profiling tool  
**Performance:** Low overhead (< 1%)  
**Latency:** Real-time profiling

**When to Use:**
- ‚úÖ Performance analysis
- ‚úÖ Hot spot identification
- ‚úÖ Cache miss analysis
- ‚úÖ CPU utilization profiling

**Z Monitor Usage:**
- **Performance analysis:** `perf record ./z-monitor`
- **Hot spot analysis:** `perf report`
- **Cache analysis:** `perf stat -e cache-misses ./z-monitor`

---

#### 3.3.3 Intel VTune / AMD uProf

**Type:** Advanced performance profiler  
**Performance:** Detailed analysis  
**Latency:** Post-processing analysis

**When to Use:**
- ‚úÖ Deep performance analysis
- ‚úÖ Memory bandwidth analysis
- ‚úÖ CPU pipeline analysis
- ‚úÖ Advanced optimization

**Z Monitor Usage:**
- **Advanced optimization** (if available on target platform)
- **Not required** for basic performance tuning

---

## 4. Decision Guidelines

### 4.1 Choosing Lock-Free Queue Libraries

**Decision Tree:**

```
Is it SPSC (Single Producer, Single Consumer)?
‚îú‚îÄ YES ‚Üí Use boost::lockfree::spsc_queue
‚îÇ         (Fastest, pre-allocated, < 10 ns)
‚îÇ
‚îî‚îÄ NO ‚Üí Is it MPSC (Multiple Producers, Single Consumer)?
    ‚îú‚îÄ YES ‚Üí Use boost::lockfree::queue OR moodycamel::ConcurrentQueue
    ‚îÇ         (boost::lockfree::queue if boost available)
    ‚îÇ         (moodycamel if header-only preferred)
    ‚îÇ
    ‚îî‚îÄ NO ‚Üí Use moodycamel::ConcurrentQueue
            (MPMC support, header-only)
```

**Z Monitor Decisions:**
- **Sensor I/O ‚Üí RT Thread:** `boost::lockfree::spsc_queue` (SPSC, highest performance)
- **RT Thread ‚Üí Database Thread:** `boost::lockfree::queue` (MPSC, if multiple RT workers)
- **Logging Queue:** `moodycamel::ConcurrentQueue` (MPSC, header-only preferred)

---

### 4.2 Choosing Memory Management Techniques

**Decision Tree:**

```
Is it in the critical path (< 50ms requirement)?
‚îú‚îÄ YES ‚Üí Pre-allocate all buffers
‚îÇ         Use object pools for temporary objects
‚îÇ         Zero allocations in hot path
‚îÇ
‚îî‚îÄ NO ‚Üí Is it high-frequency (> 1000 ops/sec)?
    ‚îú‚îÄ YES ‚Üí Use object pools
    ‚îÇ         Pre-allocate where possible
    ‚îÇ
    ‚îî‚îÄ NO ‚Üí Standard allocation acceptable
            Use smart pointers
            Qt parent-child for QObject
```

**Z Monitor Decisions:**
- **Alarm detection path:** Pre-allocated buffers, zero allocations
- **TelemetryBatch creation:** Object pool (high-frequency)
- **Background operations:** Standard allocation acceptable

---

### 4.3 Choosing Synchronization Primitives

**Decision Tree:**

```
Is it high-frequency (> 1000 ops/sec)?
‚îú‚îÄ YES ‚Üí Use lock-free structures
‚îÇ         Atomic operations
‚îÇ         Avoid mutexes
‚îÇ
‚îî‚îÄ NO ‚Üí Is it low-frequency (< 100 ops/sec)?
    ‚îú‚îÄ YES ‚Üí Mutex acceptable
    ‚îÇ         QMutex for Qt code
    ‚îÇ         std::mutex for standard C++
    ‚îÇ
    ‚îî‚îÄ NO ‚Üí Qt signals/slots (queued connection)
            Acceptable latency for UI updates
```

**Z Monitor Decisions:**
- **Sensor ‚Üí RT Thread:** Lock-free queue (high-frequency)
- **RT ‚Üí Database Thread:** Lock-free queue (high-frequency)
- **RT ‚Üí UI Thread:** Qt signals (acceptable latency, < 50ms)
- **Configuration updates:** Mutex (low-frequency)

---

## 5. Z Monitor Implementation Plan

### 5.1 Critical Path (< 50ms): Alarm Detection

**Requirements:**
- Sensor read ‚Üí sample enqueued: < 1 ms
- Sample ‚Üí processed: < 5 ms
- Alarm detection ‚Üí UI visible: < 50 ms

**Techniques:**
1. **Pre-allocated buffers:** All alarm detection structures pre-allocated
2. **Lock-free queue:** `boost::lockfree::spsc_queue` for Sensor ‚Üí RT Thread
3. **Zero allocations:** No heap allocations in alarm detection path
4. **High priority thread:** RT Thread at SCHED_FIFO priority
5. **CPU affinity:** RT Thread pinned to CPU core 0

**Libraries:**
- `boost::lockfree::spsc_queue<SensorSample, capacity<4096>>`
- Custom SPSC ring buffer for waveform samples (if needed)

**Location:**
- `src/infrastructure/sensors/WebSocketSensorDataSource.cpp` - Producer
- `src/application/services/MonitoringService.cpp` - Consumer (RT Thread)
- `src/domain/monitoring/AlarmAggregate.cpp` - Alarm detection

---

### 5.2 High-Frequency Path: Telemetry Batching

**Requirements:**
- RT Thread ‚Üí Database Thread: < 200 ms (background)
- Batch size: 10 records per transaction

**Techniques:**
1. **Lock-free queue:** `boost::lockfree::queue` for MPSC
2. **Object pooling:** Pool of TelemetryBatch objects
3. **Batch processing:** Group 10 records per database transaction
4. **Move semantics:** Move batches, don't copy

**Libraries:**
- `boost::lockfree::queue<TelemetryBatch>`
- Custom `ObjectPool<TelemetryBatch>` (100 objects)

**Location:**
- `src/application/services/MonitoringService.cpp` - Producer (RT Thread)
- `src/infrastructure/persistence/SQLiteTelemetryRepository.cpp` - Consumer (Database Thread)
- `src/infrastructure/utils/ObjectPool.h/cpp` - Object pool implementation

---

### 5.3 High-Frequency Path: Logging

**Requirements:**
- Log entry enqueue: < 1 ms
- Background flush: < 200 ms

**Techniques:**
1. **Lock-free queue:** `moodycamel::ConcurrentQueue` for MPSC
2. **Pre-allocated buffers:** LogBuffer for message construction
3. **Batch writes:** Flush multiple entries per file write

**Libraries:**
- `moodycamel::ConcurrentQueue<LogEntry>`
- Custom `LogBuffer` (pre-allocated 1KB buffer)

**Location:**
- `src/infrastructure/logging/LogService.cpp` - Producer (all threads, enqueues to lock-free queue)
- `src/infrastructure/logging/LogService.cpp` - Consumer (Database I/O Thread)
- `src/infrastructure/utils/LogBuffer.h/cpp` - Log buffer implementation

---

### 5.4 Real-Time Path: Waveform Display

**Requirements:**
- Waveform sample ‚Üí display: < 16 ms (60 FPS)
- Smooth rendering without jitter

**Techniques:**
1. **Pre-allocated circular buffer:** 30-second waveform cache
2. **Lock-free access:** Atomic indices for buffer access
3. **Zero-copy rendering:** QML Canvas API with direct buffer access
4. **Double buffering:** Separate read/write buffers

**Libraries:**
- Custom `WaveformCache` (circular buffer)
- Qt QML Canvas API

**Location:**
- `src/infrastructure/caching/WaveformCache.h/cpp` - Circular buffer
- `src/interface/qml/components/WaveformDisplay.qml` - QML rendering

---

### 5.5 Background Path: Database Writes

**Requirements:**
- Batch write: < 200 ms (background)
- Critical alarm write: < 100 ms (immediate)

**Techniques:**
1. **Batch processing:** 10 records per transaction
2. **Prepared statements:** Reuse SQL statements
3. **WAL mode:** SQLite WAL for concurrent reads
4. **Normal priority:** Database thread at normal priority

**Libraries:**
- SQLite with WAL mode
- QxOrm or custom prepared statements

**Location:**
- `src/infrastructure/persistence/SQLiteVitalsRepository.cpp`
- `src/infrastructure/persistence/DatabaseManager.cpp`

---

## 6. Performance Guidelines

### 6.1 Critical Path Guidelines

**DO:**
- ‚úÖ Pre-allocate all buffers at startup
- ‚úÖ Use lock-free structures for inter-thread communication
- ‚úÖ Set high thread priority for RT threads
- ‚úÖ Pin RT threads to CPU cores
- ‚úÖ Use zero-copy patterns (move semantics, references)
- ‚úÖ Measure latency continuously

**DON'T:**
- ‚ùå Allocate memory in critical path
- ‚ùå Use mutexes in high-frequency operations
- ‚ùå Copy large data structures
- ‚ùå Block RT threads with I/O operations
- ‚ùå Use dynamic containers that grow

---

### 6.2 Measurement Guidelines

**DO:**
- ‚úÖ Measure latency at 95th and 99th percentiles
- ‚úÖ Monitor jitter (variance in latency)
- ‚úÖ Track latency trends over time
- ‚úÖ Set up automated regression detection
- ‚úÖ Profile with `perf` or similar tools

**DON'T:**
- ‚ùå Rely on average latency only
- ‚ùå Ignore tail latencies (99th percentile)
- ‚ùå Measure in debug builds
- ‚ùå Measure with other processes running

---

### 6.3 Optimization Guidelines

**DO:**
- ‚úÖ Profile before optimizing
- ‚úÖ Measure impact of optimizations
- ‚úÖ Optimize critical path first
- ‚úÖ Use appropriate tools for each scenario
- ‚úÖ Document performance characteristics

**DON'T:**
- ‚ùå Premature optimization
- ‚ùå Optimize non-critical paths
- ‚ùå Sacrifice code clarity for micro-optimizations
- ‚ùå Optimize without measurement

---

## 7. Library Dependencies

### 7.1 Required Libraries

| Library | Purpose | License | Dependency Type |
|---------|---------|---------|----------------|
| `boost::lockfree` | Lock-free queues | Boost License | Required for SPSC/MPSC queues |
| `moodycamel::ConcurrentQueue` | Lock-free queue (alternative) | Public Domain | Optional (header-only alternative) |

### 7.2 Optional Libraries

| Library | Purpose | License | When to Use |
|---------|---------|---------|-------------|
| `boost::pool` | Memory pooling | Boost License | If boost available and custom pool not needed |
| `Google Benchmark` | Performance benchmarks | Apache 2.0 | CI/CD performance testing |

---

## 8. Testing and Validation

### 8.1 Latency Testing

**Tools:**
- Google Benchmark for microbenchmarks
- Custom latency measurement in production code
- `perf` for profiling

**Test Scenarios:**
- Alarm detection latency (< 50ms)
- Queue throughput (operations/second)
- Memory allocation overhead
- Thread priority effectiveness

**See:** [40_BENCHMARK_AND_PERFORMANCE_MEASUREMENT.md](./40_BENCHMARK_AND_PERFORMANCE_MEASUREMENT.md)

---

### 8.2 Regression Testing

**Automated:**
- Nightly benchmark execution
- Latency regression detection
- Performance trend analysis

**Manual:**
- Profiling with `perf` on target hardware
- Stress testing under load
- Jitter analysis

---

## 9. Related Documents

- [12_THREAD_MODEL.md](./12_THREAD_MODEL.md) - Thread architecture and latency targets ‚≠ê
- [23_MEMORY_RESOURCE_MANAGEMENT.md](./23_MEMORY_RESOURCE_MANAGEMENT.md) - Memory management patterns
- [36_DATA_CACHING_STRATEGY.md](./36_DATA_CACHING_STRATEGY.md) - Critical path caching
- [40_BENCHMARK_AND_PERFORMANCE_MEASUREMENT.md](./40_BENCHMARK_AND_PERFORMANCE_MEASUREMENT.md) - Performance measurement
- [Performance Requirements](../../requirements/04_NON_FUNCTIONAL_REQUIREMENTS.md) - Latency targets

---

**Document Version:** 1.0  
**Last Updated:** 2025-11-27  
**Status:** Approved

*This document provides comprehensive guidance for implementing low-latency operations in the Z Monitor application. Follow the decision guidelines and implementation plans for each critical path.*
